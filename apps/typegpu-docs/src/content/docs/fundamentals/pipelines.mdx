---
title: Pipelines
description: A guide on how to use TypeGPU render and compute pipelines.
---

:::caution[Experimental]
Pipelines are an *unstable* feature. The API may be subject to change in the near future.
:::

:::note[Recommended reading]
It is assumed that you are familiar with the following concepts:
- <a href="https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html" target="_blank" rel="noopener noreferrer">WebGPU Fundamentals</a>
- [TypeGPU Functions](/TypeGPU/fundamentals/functions)
:::

TypeGPU introduces a custom API to easily define and execute render and compute pipelines.
It abstracts away the standard WebGPU procedures to offer a convenient, type-safe way to run shaders on the GPU.

## Creating pipelines

A pipeline can be defined with one of the following methods on the [root](/TypeGPU/fundamentals/roots) object:
- [createRenderPipeline](#createrenderpipeline)
- [createComputePipeline](#createcomputepipeline)
- [createGuardedComputePipeline](#createguardedcomputepipeline)

```ts twoslash
/// <reference types="@webgpu/types" />
import tgpu, { d } from 'typegpu';

const root = await tgpu.init();

const presentationFormat = 'rgba8unorm';

const mainVertex = tgpu.vertexFn({
  in: { vertexIndex: d.builtin.vertexIndex },
  out: { pos: d.builtin.position },
})((input) => {
  const pos = [d.vec2f(-1, -1), d.vec2f(3, -1), d.vec2f(-1, 3)];

  return {
    pos: d.vec4f(pos[input.vertexIndex], 0, 1),
  };
});

const mainFragment = tgpu.fragmentFn({ out: d.vec4f })(() => d.vec4f(1, 0, 0, 1));

const mainCompute = tgpu.computeFn({ workgroupSize: [1] })(() => {});

// ---cut---
const renderPipeline = root.createRenderPipeline({
  vertex: mainVertex,
  fragment: mainFragment,
  targets: { format: presentationFormat },
});

const computePipeline1 = root.createComputePipeline({
  compute: mainCompute,
});

const computePipeline2 = root.createGuardedComputePipeline((x, y, z) => {
  'use gpu';
  // ...
});
```

### createRenderPipeline

The `createRenderPipeline` method creates a render pipeline by accepting an options object that specifies the vertex function, fragment function, targets, and optional additional settings.

- `vertex`: The `TgpuVertexFn` or `'use gpu'` callback to use as the vertex shader.
- `fragment`: The `TgpuFragmentFn` or `'use gpu'` callback to use as the fragment shader.
- `targets`: A record defining the formats and behaviors of the color targets, similar to WebGPU's `GPUColorTargetState`, but as a record with named targets.
- `depthStencil` (optional): Depth-stencil state, same as WebGPU's `GPUDepthStencilState`.
- `multisample` (optional): Multisample state, same as WebGPU's `GPUMultisampleState`.
- `primitive` (optional): Primitive state, same as WebGPU's `GPUPrimitiveState`.

The vertex function's input parameters (non-builtin) are matched to vertex attributes specified in the pipeline's vertex layout when executing. Vertex attributes are validated at the type level for compatibility.

```ts twoslash
import tgpu, { d } from 'typegpu';

const root = await tgpu.init();
const presentationFormat = 'rgba8unorm';

const mainVertex = tgpu.vertexFn({
  in: { vertexIndex: d.builtin.vertexIndex, pos: d.vec2f },
  out: { pos: d.builtin.position },
})((input) => {
  const pos = [d.vec2f(-1, -1), d.vec2f(3, -1), d.vec2f(-1, 3)];

  return {
    pos: d.vec4f(pos[input.vertexIndex], 0, 1),
  };
});

const mainFragment = tgpu.fragmentFn({ out: d.vec4f })(() => d.vec4f(1, 0, 0, 1));
// ---cut---
const vertexLayout = tgpu.vertexLayout(d.arrayOf(d.vec2f));

const renderPipeline = root.createRenderPipeline({
  attribs: { pos: vertexLayout.attrib },
  vertex: mainVertex,
  fragment: mainFragment,
  targets: { format: presentationFormat },
  // Additional options can be specified here
  depthStencil: {
    format: 'depth24plus',
    depthWriteEnabled: true,
    depthCompare: 'less',
  },
  multisample: {
    count: 4,
  },
  primitive: { topology: 'triangle-list' },
});
```



#### Type-level validation

Using the pipelines should ensure the compatibility of the vertex output and fragment input on the type level.
These parameters are identified by their names, not by their numeric *location* index.
In general, when using vertex and fragment functions with TypeGPU pipelines, it is not necessary to set locations on the IO struct properties.
The library automatically matches up the corresponding members (by their names) and assigns common locations to them.
When a custom location is provided by the user (via the `d.location` attribute function) it is respected by the automatic assignment procedure,
as long as there is no conflict between vertex and fragment location values.

```ts twoslash
import tgpu, { d } from 'typegpu';

const vertex = tgpu.vertexFn({
  out: { pos: d.builtin.position },
})`(...)`;
const fragment = tgpu.fragmentFn({
  in: { uv: d.vec2f },
  out: d.vec4f,
})`(...)`;

const root = await tgpu.init();

// @errors: 2769
root.createRenderPipeline({
  vertex,
  fragment,
  targets: { format: 'bgra8unorm' },
});
```



### createComputePipeline

The `createComputePipeline` method creates a compute pipeline by accepting an options object with the compute function.

- `compute`: The `TgpuComputeFn` to use as the compute shader.

```ts twoslash
import tgpu, { d } from 'typegpu';

const root = await tgpu.init();

const mainCompute = tgpu.computeFn({ workgroupSize: [1] })(() => {});

// ---cut---
const computePipeline = root.createComputePipeline({
  compute: mainCompute,
});
```

:::caution
The underlying WebGPU resources for TypeGPU pipelines are created lazily, just before the first execution or as part of a `root.unwrap`, not immediately after the `createRenderPipeline` or `createComputePipeline` invocation.
:::


### createGuardedComputePipeline

The `createGuardedComputePipeline` method streamlines running simple computations on the GPU. 
Instead of dispatching workgroups, the guarded pipeline allows calling an exact number of GPU threads. Think of it as a parallelized `for` loop.
Under the hood, it creates a compute pipeline that calls the provided callback only if the current thread ID is within the requested range.

```ts twoslash
import tgpu, { d } from 'typegpu';
const root = await tgpu.init();
// ---cut---
const data = root.createMutable(d.arrayOf(d.u32, 8), [0, 1, 2, 3, 4, 5, 6, 7]);

const doubleUpPipeline = root.createGuardedComputePipeline((x) => {
  'use gpu';
  data.$[x] *= 2;
});

doubleUpPipeline.dispatchThreads(8);
doubleUpPipeline.dispatchThreads(8);
doubleUpPipeline.dispatchThreads(5);

// the command encoder will queue the read after `doubleUpPipeline`
console.log(await data.read()); // [0, 8, 16, 24, 32, 20, 24, 28]
```

:::tip
When using guarded compute pipelines, it is impossible to change workgroup sizes, or use builtins.
The default workgroup sizes are:

- `[1, 1, 1]` for 0D dispatches,
- `[256, 1, 1]` for 1D dispatches,
- `[16, 16, 1]` for 2D dispatches,
- `[8, 8, 4]` for 3D dispatches.
:::

The callback can have up to three arguments (dimensions).
`createGuardedComputePipeline` can simplify writing a pipeline helping reduce serialization overhead when initializing buffers with data.
Buffer initialization commonly uses random number generators.
For that, you can use the [`@typegpu/noise`](TypeGPU/ecosystem/typegpu-noise) library.

```ts twoslash
import tgpu, { d } from 'typegpu';
// ---cut---
import { randf } from '@typegpu/noise';

const root = await tgpu.init();

// buffer of 1024x512 floats
const waterLevelMutable = root.createMutable(
  d.arrayOf(d.arrayOf(d.f32, 512), 1024),
);

root.createGuardedComputePipeline((x, y) => {
  'use gpu';
  randf.seed2(d.vec2f(x, y).div(1024));
  waterLevelMutable.$[x][y] = 10 + randf.sample();
}).dispatchThreads(1024, 512);
// callback will be called for x in range 0..1023 and y in range 0..511

// (optional) read values in JS
console.log(await waterLevelMutable.read());
```

:::note
`TgpuGuardedComputePipeline` provides getters for the underlying pipeline and the size buffer.
Those might be useful for `tgpu.resolve`, since you cannot resolve a guarded pipeline directly.

```ts
const innerPipeline = doubleUpPipeline.with(bindGroup1).pipeline;
tgpu.resolve([innerPipeline]);
```
:::

## Execution

```ts
renderPipeline
  .withColorAttachment({ view: context })
  .draw(3);

computePipeline.dispatchWorkgroups(16);

guardedComputePipeline.dispatchThreads(4);
```

### Attachments

Render pipelines require specifying a color attachment for each target.
The attachments are specified in the same way as in the WebGPU API (but accept both TypeGPU resources and regular WebGPU ones). However, similar to the *targets* argument, multiple targets need to be passed in as a record, with each target identified by name.

Similarly, when using `withDepthStencil` it is necessary to pass in a depth stencil attachment, via the `withDepthStencilAttachment` method.

```ts
renderPipeline
  .withColorAttachment({
    color: {
      view: msaaTextureView,
      resolveTarget: context,
      loadOp: 'clear',
      storeOp: 'store',
    },
    shadow: {
      view: shadowTextureView,
      clearValue: [1, 1, 1, 1],
      loadOp: 'clear',
      storeOp: 'store',
    },
  })
  .withDepthStencilAttachment({
    view: depthTextureView,
    depthClearValue: 1,
    depthLoadOp: 'clear',
    depthStoreOp: 'store',
  })
  .draw(vertexCount);
```

### Resource bindings

Before executing pipelines, it is necessary to bind all of the utilized resources, like bind groups, vertex buffers and slots. It is done using the `with` method. It accepts either [a bind group](/TypeGPU/fundamentals/bind-groups) (render and compute pipelines) or [a vertex layout and a vertex buffer](/TypeGPU/fundamentals/vertex-layouts) (render pipelines only).

```ts
// vertex layout
const vertexLayout = tgpu.vertexLayout(
  d.disarrayOf(d.float16),
  'vertex',
);
const vertexBuffer = root
  .createBuffer(d.disarrayOf(d.float16, 8), [0, 0, 1, 0, 0, 1, 1, 1])
  .$usage('vertex');

// bind group layout
const bindGroupLayout = tgpu.bindGroupLayout({
  size: { uniform: d.vec2u },
});

const sizeBuffer = root
  .createBuffer(d.vec2u, d.vec2u(64, 64))
  .$usage('uniform');

const bindGroup = root.createBindGroup(bindGroupLayout, {
  size: sizeBuffer,
});

// binding and execution
renderPipeline
  .with(vertexLayout, vertexBuffer)
  .with(bindGroup)
  .draw(8);

computePipeline
  .with(bindGroup)
  .dispatchWorkgroups(1);
```

### Timing performance

Pipelines also expose the `withPerformanceCallback` and `withTimestampWrites` methods for timing the execution time on the GPU.
For more info about them, refer to the [Timing Your Pipelines guide](/TypeGPU/fundamentals/timestamp-queries/).

### *draw*, *dispatchWorkgroups*

After creating the render pipeline and setting all of the attachments, it can be put to use by calling the `draw` method.
It accepts the number of vertices and optionally the instance count, first vertex index and first instance index.
After calling the method, the shader is set for execution immediately.

Compute pipelines are executed using the `dispatchWorkgroups` method, which accepts the number of workgroups in each dimension.

### Drawing with `drawIndexed`

The `drawIndexed` is analogous to draw, but takes advantage of [index buffer](/TypeGPU/fundamentals/buffers/#index-buffers) to explicitly map vertex data onto primitives. When using an index buffer, you don't need to list every vertex for every primitive explicitly. Instead, you provide a list of unique vertices in a vertex buffer. Then, the index buffer defines how these vertices are connected to form primitives.

```ts twoslash
import tgpu, { d } from 'typegpu';

const root = await tgpu.init();
const presentationFormat = "rgba8unorm";

const colorBuffer = root
  .createBuffer(d.arrayOf(d.vec4f, 4), [
    d.vec4f(1, 0, 0, 1), // Red
    d.vec4f(0, 1, 0, 1), // Green
    d.vec4f(0, 0, 1, 1), // Blue
    d.vec4f(1, 1, 0, 1), // Yellow
  ])
  .$usage('vertex');

const vertex = tgpu.vertexFn({
  in: {
    idx: d.builtin.vertexIndex,
    color: d.vec4f,
  },
  out: {
    color: d.vec4f,
    pos: d.builtin.position,
  },
})(({ idx, color }) => {
  return {
    color,
    pos: d.vec4f(d.vec2f(1, 1), 1, 1),
  };
});

const vertexLayout = tgpu.vertexLayout(d.arrayOf(d.vec4f));
const mainFragment = tgpu.fragmentFn({
  in: {
    color: d.vec4f,
  },
  out: d.vec4f,
})((input) => input.color);
// ---cut---
const indexBuffer = root
  .createBuffer(d.arrayOf(d.u16, 6), [0, 2, 1, 0, 3, 2])
  .$usage('index');

const pipeline = root
  .createRenderPipeline({
    attribs: { color: vertexLayout.attrib },
    vertex,
    fragment: mainFragment,
    targets: { format: presentationFormat },
  })
  .withIndexBuffer(indexBuffer);

  pipeline
    .with(vertexLayout, colorBuffer)
    .drawIndexed(6);
```

## Low-level render pipeline execution API

The higher-level API has several limitations, therefore another way of executing pipelines is exposed, for some custom, more demanding scenarios. For example, with the high-level API, it is not possible to execute multiple pipelines per one render pass. It also may be missing some more niche features of the WebGPU API.

`root['~unstable'].beginRenderPass` is a method that mirrors the WebGPU API, but enriches it with a direct TypeGPU resource support.

```ts
root['~unstable'].beginRenderPass(
  {
    colorAttachments: [{
      ...
    }],
  },
  (pass) => {
    pass.setPipeline(renderPipeline);
    pass.setBindGroup(layout, group);
    pass.draw(3);
  },
);
```

It is also possible to access the underlying WebGPU resources for the TypeGPU pipelines, by calling `root.unwrap(pipeline)`.
That way, they can be used with a regular WebGPU API, but unlike the `root['~unstable'].beginRenderPass` API, it also requires unwrapping all the necessary
resources.

```ts twoslash
import tgpu, { d } from 'typegpu';

const root = await tgpu.init();

const mainVertex = tgpu.vertexFn({ out: { pos: d.builtin.position } })`...`;
const mainFragment = tgpu.fragmentFn({ out: d.vec4f })`...`;

// ---cut---
const pipeline = root.createRenderPipeline({
  vertex: mainVertex,
  fragment: mainFragment,
  targets: { format: 'rg8unorm' },
});

const rawPipeline = root.unwrap(pipeline);
//    ^?
```
