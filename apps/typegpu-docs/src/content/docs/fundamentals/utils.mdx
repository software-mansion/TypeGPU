---
title: Utilities
description: A list of various utilities provided by TypeGPU.
---

## *prepareDispatch*

The `prepareDispatch` function streamlines running simple computations on the GPU.
Under the hood, it wraps the callback in a `TgpuFn`, creates a compute pipeline, and returns an object with dispatch method that executes the pipeline.
Since the pipeline is reused, there’s no additional overhead for subsequent calls.

```ts twoslash
import tgpu, { prepareDispatch } from 'typegpu';
import * as d from 'typegpu/data';
const root = await tgpu.init();
// ---cut---
const data = root.createMutable(d.arrayOf(d.u32, 8), [0, 1, 2, 3, 4, 5, 6, 7]);

const doubleUp = prepareDispatch(root, (x) => {
  'kernel';
  data.$[x] *= 2;
});

doubleUp.dispatch(8);
doubleUp.dispatch(8);
doubleUp.dispatch(4);

// the command encoder will queue the read after `doubleUp`
console.log(await data.read()); // [0, 8, 16, 24, 16, 20, 24, 28]
```

:::note
Remember to mark the callback with `'kernel'` directive to let TypeGPU know that this function is TGSL.
:::

The callback can have up to three arguments (dimensions).
`prepareDispatch` can simplify writing a pipeline helping reduce serialization overhead when initializing buffers with data.
Buffer initialization commonly uses random number generators.
For that, you can use the [`@typegpu/noise`](TypeGPU/ecosystem/typegpu-noise) library.

```ts twoslash
import tgpu, { prepareDispatch } from 'typegpu';
import * as d from 'typegpu/data';
// ---cut---
import { randf } from '@typegpu/noise';

const root = await tgpu.init();

// buffer of 1024x512 floats
const waterLevelMutable = root.createMutable(
  d.arrayOf(d.arrayOf(d.f32, 512), 1024),
);

prepareDispatch(root, (x, y) => {
  'kernel';
  randf.seed2(d.vec2f(x, y).div(1024));
  waterLevelMutable.$[x][y] = 10 + randf.sample();
}).dispatch(1024, 512);
// callback will be called for x in range 0..1023 and y in range 0..511

// (optional) read values in JS
console.log(await waterLevelMutable.read());
```

Analogously to `TgpuComputePipeline`, the result of `prepareDispatch` can have bind groups bound using the `with` method.

```ts twoslash
import tgpu, { prepareDispatch } from 'typegpu';
import * as d from 'typegpu/data';
import * as std from 'typegpu/std';
const root = await tgpu.init();
// ---cut---
const layout = tgpu.bindGroupLayout({
  buffer: { storage: d.arrayOf(d.u32), access: 'mutable' },
});
const buffer1 = root
  .createBuffer(d.arrayOf(d.u32, 3), [1, 2, 3]).$usage('storage');
const buffer2 = root
  .createBuffer(d.arrayOf(d.u32, 4), [2, 4, 8, 16]).$usage('storage');
const bindGroup1 = root.createBindGroup(layout, {
  buffer: buffer1,
});
const bindGroup2 = root.createBindGroup(layout, {
  buffer: buffer2,
});

const test = prepareDispatch(root, (x) => {
  'kernel';
  layout.$.buffer[x] *= 2;
});

test.with(layout, bindGroup1).dispatch(3);
test.with(layout, bindGroup2).dispatch(4);

console.log(await buffer1.read()); // [2, 4, 6];
console.log(await buffer2.read()); // [4, 8, 16, 32];
```

It is recommended NOT to use `prepareDispatch` for:

- More complex compute shaders.
When using `prepareDispatch`, it is impossible to change workgroup sizes or to use [slots](/TypeGPU/fundamentals/slots).
For such cases, a manually created pipeline would be more suitable.

- Small calls.
Usually, for small data the shader creation and dispatch is more costly than serialization.
Small buffers can be more efficiently initialized with the `buffer.write()` method.

:::note
The default workgroup sizes are:

- `[1, 1, 1]` for 0D dispatches,
- `[256, 1, 1]` for 1D dispatches,
- `[16, 16, 1]` for 2D dispatches,
- `[8, 8, 4]` for 3D dispatches.

The callback is not called if the global invocation id of a thread would exceed the size in any dimension.
:::

## *batch*
By default, TypeGPU pipelines and render passes are submitted to the GPU immediately.
If you want to give the GPU an opportunity to better utilize its resources,
you can use the `batch` function.

The `batch` function allows you to submit multiple pipelines and render passes to the GPU in a single call.
Under the hood, it creates `GPUCommandEncoder`,
records the commands from the provided callback function,
and submits the resulting `GPUCommandBuffer` to the device.

:::caution
Read–write operations always flush the command encoder (flushing means finalizing the command encoder and submitting the resulting command buffer to the GPU) inside the batch environment. Outside they don't have to, everything is already flushed. We've prepared a table showing when a flush occurs (i.e., when a new command encoder is created). Keep this in mind when using `batch`.
:::

| Invocation                                      | Inside batch env    | Outside batch env  |
|-------------------------------------------------|---------------------|--------------------|
| `pipeline.draw`                                 | No Flush ❌         | Flush ✅           |
| `pipeline.drawIndexed`                          | No Flush ❌         | Flush ✅           |
| `pipeline.dispatchWorkgroups`                   | No Flush ❌         | Flush ✅           |
| `pipeline.withPerformanceCallback`              | No Flush ❌ / ⚠️ ⬇️ | Flush ✅           |
| `pipeline.withTimestampWrites`                  | No Flush ❌         | Flush ✅           |
| `beginRenderPass`                               | No Flush ❌         | Flush ✅           |
| `buffer.write`                                  | Flush ✅            | No Flush ❌        |
| `buffer.writePartial`                           | Flush ✅            | No Flush ❌        |
| `buffer.read`                                   | Flush ✅            | No Flush ❌        |
| `querySet.resolve`                              | No Flush ❌         | No Flush ❌        |
| `querySet.read`                                 | Flush ✅            | Flush ✅           |
| `pipeline containing console.log`               | Flush ✅            | Flush ✅           |
| `prepareDispatch().dispatch`                    | No flush ❌         | Flush ✅           |
| `nested batch`                                  | Flush ✅            | N/A                |


:::caution
When you call a pipeline with a performance callback, the callback is invoked at the end of the batch. The timestamps themselves are not affected by the batching. They are still written at the beginning and/or end of the associated pipeline/render pass.
:::

:::caution
`querySet.resolve` itself never flushes.
- If you need to read from it, `querySet.read` will handle the flush.
- If you use it on the GPU, another function will flush the existing `commandEncoder` with the `querySet.resolve` command.
This works because we never create a new `commandEncoder` unless it's necessary.
:::

### Example
```ts twoslash
import tgpu from 'typegpu';
import * as d from 'typegpu/data';

const entryFn = tgpu['~unstable'].computeFn({ workgroupSize: [7] })(() => {});
const vertexFn = tgpu['~unstable'].vertexFn({
  out: { pos: d.builtin.position },
})(() => {
  return { pos: d.vec4f() };
});
const fragmentFn = tgpu['~unstable'].fragmentFn({
  out: d.vec4f,
})(() => d.vec4f());

const root = await tgpu.init();

const renderPipeline = root['~unstable']
  .withVertex(vertexFn, {})
  .withFragment(fragmentFn, { format: 'rgba8unorm' })
  .createPipeline();

const computePipeline = root['~unstable']
  .withCompute(entryFn)
  .createPipeline();

const buffer = root.createBuffer(d.arrayOf(d.f32, 1024));

// ---cut---
const render = () => {
  computePipeline.dispatchWorkgroups(7, 7, 7);
  renderPipeline.draw(777);
  // more operations...

  buffer.write(Array.from({ length: 1024 }, () => Math.random()));
  // force flush caused by write, new command encoder
};

root['~unstable'].batch(render);
```

:::note
The batch callback must be synchronous.
While this constraint may appear restrictive, the recommended approach is to divide
the batch into multiple separate batches if asynchronous operations are required.
:::

:::danger
Nested batching is not supported and will result in a runtime error.
:::

## *console.log*

Yes, you read that correctly, TypeGPU implements logging to the console on the GPU!
Just call `console.log` like you would in plain JavaScript, and open the console to see the results.

```ts twoslash
import tgpu, { prepareDispatch } from 'typegpu';
import * as d from 'typegpu/data';

const root = await tgpu.init();
// ---cut---
const callCountMutable = root.createMutable(d.u32, 0);
const compute = prepareDispatch(root, () => {
  'kernel';
  callCountMutable.$ += 1;
  console.log('Call number', callCountMutable.$);
});

compute.dispatch();
compute.dispatch();

// Eventually...
// "[GPU] Call number 1"
// "[GPU] Call number 2"
```

Currently supported data types for logging include scalars, vectors, matrices, structs, and fixed-size arrays.

Under the hood, TypeGPU translates `console.log` to a series of serializing functions that write the logged arguments to a buffer that is read and deserialized after every draw/dispatch call.

The buffer is of fixed size, which may limit the total amount of information that can be logged; if the buffer overflows, additional logs are dropped.
If that's an issue, you may specify the size manually when creating the `root` object.

```ts twoslash
import tgpu, { prepareDispatch } from 'typegpu';
import * as d from 'typegpu/data';

const presentationFormat = undefined as any;
const canvas = undefined as any;
const context = canvas.getContext('webgpu') as any;
// ---cut---
const root = await tgpu.init({
  unstable_logOptions: {
    logCountLimit: 32,
    logSizeLimit: 8, // in bytes, enough to fit 2*u32
  },
});

/* vertex shader */

const mainFragment = tgpu['~unstable'].fragmentFn({
  in: { pos: d.builtin.position },
  out: d.vec4f,
})(({ pos }) => {
  // this log fits in 8 bytes
  // static strings do not count towards the serialized log size
  console.log('X:', d.u32(pos.x), 'Y:', d.u32(pos.y));
  return d.vec4f(0, 1, 1, 1);
});

/* pipeline creation and draw call */
```

:::note
The logs are written to console only after the dispatch finishes and the buffer is read.
This may happen with a noticeable delay.
:::

:::caution
When using `console.log`, atomic operations are injected into the WGSL code to safely synchronize logging from multiple threads.
This synchronization can introduce overhead and significantly impact shader performance.
:::

There are some limitations (some of which we intend to alleviate in the future):

- `console.log` only works when used in TGSL, when calling or resolving a TypeGPU pipeline.
Otherwise, for example when using `tgpu.resolve` on a WGSL template, logs are ignored.
- `console.log` only works in fragment and compute shaders.
This is due to a [WebGPU limitation](https://www.w3.org/TR/WGSL/#address-space) that does not allow modifying buffers during the vertex shader stage.
- `console.log` currently does not support template literals and string substitutions.
- Other `console` methods like `clear` or `warn` are not yet supported.
